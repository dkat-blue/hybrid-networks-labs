{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Neural Networks Lab using PyTorch\n",
    " \n",
    "This notebook implements three models:\n",
    " \n",
    "1. **MLP Model**: A standard multilayer perceptron with two hidden layers.\n",
    "2. **RBF Model**: A network using a custom Radial Basis Function (RBF) layer.\n",
    "3. **Hybrid Model**: A model that takes the penultimate output of a pretrained MLP, feeds it into an RBF layer, then into a final classification layer.\n",
    "\n",
    "Two datasets are used for experimentation: the Iris dataset and Fashion MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# For data loading\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom RBF Layer\n",
    "\n",
    "The `RBFLayer` computes Gaussian activations for each unit based on trainable centers and beta (width) parameters.\n",
    "\n",
    "The output for an input vector $x$ is computed as:\n",
    "\n",
    "$$\n",
    "\\text{output}_i = \\exp\\Big(-\\beta_i \\cdot \\|x - c_i\\|^2\\Big)\n",
    "$$\n",
    "\n",
    "where $c_i$ is the trainable center for the $i$-th unit and $\\beta_i$ is the trainable width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, gamma=1.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_features (int): Dimensionality of the input.\n",
    "            out_features (int): Number of RBF units.\n",
    "            gamma (float): Initial value for beta parameters.\n",
    "        \"\"\"\n",
    "        super(RBFLayer, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        # Initialize centers randomly.\n",
    "        self.centers = nn.Parameter(torch.randn(out_features, in_features))\n",
    "        # Initialize betas with the constant gamma.\n",
    "        self.betas = nn.Parameter(torch.full((out_features,), gamma))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, in_features)\n",
    "        # Expand dimensions to compute the Euclidean distance between x and each center.\n",
    "        # x_expanded: (batch, 1, in_features)\n",
    "        # centers_expanded: (1, out_features, in_features)\n",
    "        x_expanded = x.unsqueeze(1)\n",
    "        centers_expanded = self.centers.unsqueeze(0)\n",
    "        diff = x_expanded - centers_expanded  # (batch, out_features, in_features)\n",
    "        l2 = torch.sum(diff ** 2, dim=2)  # (batch, out_features)\n",
    "        # Compute Gaussian RBF activation: exp(-beta * ||x - center||^2)\n",
    "        return torch.exp(-self.betas * l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definitions\n",
    "\n",
    "We define three models:\n",
    "\n",
    "1. **MLP:** Two hidden layers with a selectable activation function.\n",
    "2. **RBFNetwork:** Uses the custom RBF layer followed by a linear classification layer.\n",
    "3. **HybridNetwork:** Uses a pretrained MLPâ€™s penultimate layer output as input to an RBF layer and then a classification layer. We use a skip connection between the MLP layer and the classification layer, otherwise the model doesn't learn at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom activation functions\n",
    "class Sinusoid(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.sin(x)\n",
    "\n",
    "class StepFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return (input > 0).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Straight-Through Estimator: simply pass the gradient through.\n",
    "        input, = ctx.saved_tensors\n",
    "        return grad_output\n",
    "\n",
    "class StepActivation(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return StepFunction.apply(x)\n",
    "\n",
    "# MLP model with multiple activation functions support\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden1=64, hidden2=32, num_classes=3, activation='relu'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): Input feature dimension.\n",
    "            hidden1 (int): Number of units in the first hidden layer.\n",
    "            hidden2 (int): Number of units in the second (penultimate) hidden layer.\n",
    "            num_classes (int): Number of output classes.\n",
    "            activation (str): Activation function to use. Supported values are:\n",
    "                              'relu', 'tanh', 'sigmoid' (or 'logistic'),\n",
    "                              'identity', 'softplus', 'elu', 'prelu', 'sinusoid', 'step'.\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.out = nn.Linear(hidden2, num_classes)\n",
    "        \n",
    "        act = activation.lower()\n",
    "        if act == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif act == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif act in ['sigmoid', 'logistic']:\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif act == 'identity':\n",
    "            self.activation = nn.Identity()\n",
    "        elif act == 'softplus':\n",
    "            self.activation = nn.Softplus()\n",
    "        elif act == 'elu':\n",
    "            self.activation = nn.ELU()\n",
    "        elif act == 'prelu':\n",
    "            self.activation = nn.PReLU()\n",
    "        elif act == 'sinusoid':\n",
    "            self.activation = Sinusoid()\n",
    "        elif act == 'step':\n",
    "            self.activation = StepActivation()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function: \" + activation)\n",
    "\n",
    "    def forward(self, x, return_hidden=False):\n",
    "        a1 = self.activation(self.fc1(x))\n",
    "        a2 = self.activation(self.fc2(a1))\n",
    "        out = self.out(a2)\n",
    "        if return_hidden:\n",
    "            return a2, out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, rbf_units=32, num_classes=3, gamma=1.0):\n",
    "        \"\"\"\n",
    "        RBF network using the custom RBFLayer.\n",
    "        \"\"\"\n",
    "        super(RBFNetwork, self).__init__()\n",
    "        self.rbf = RBFLayer(input_dim, rbf_units, gamma=gamma)\n",
    "        self.fc = nn.Linear(rbf_units, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.rbf(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HybridNetwork Definition\n",
    "class HybridNetwork(nn.Module):\n",
    "    def __init__(self, mlp, hidden_dim, rbf_units, num_classes, gamma):\n",
    "        \"\"\"\n",
    "        Hybrid network with a skip connection:\n",
    "          - Extracts features from the MLP's penultimate layer.\n",
    "          - Normalizes those features.\n",
    "          - Passes the normalized features through an RBF layer.\n",
    "          - Concatenates the normalized features with the RBF output.\n",
    "          - Feeds the combined representation to a final linear layer.\n",
    "          \n",
    "        This design provides a direct gradient path from the MLP features to the output.\n",
    "        \"\"\"\n",
    "        super(HybridNetwork, self).__init__()\n",
    "        self.mlp = mlp  # MLP is trained end-to-end (not frozen)\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.rbf = RBFLayer(hidden_dim, rbf_units, gamma=gamma)\n",
    "        self.fc = nn.Linear(hidden_dim + rbf_units, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features, _ = self.mlp.forward(x, return_hidden=True)\n",
    "        features_norm = self.norm(features)\n",
    "        rbf_out = self.rbf(features_norm)\n",
    "        # Concatenate along the feature dimension.\n",
    "        combined = torch.cat([features_norm, rbf_out], dim=1)\n",
    "        out = self.fc(combined)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Functions\n",
    "\n",
    "Two functions are provided:\n",
    "\n",
    "1. **load_iris_data:** Loads the Iris dataset, standardizes it, and creates DataLoaders.\n",
    "2. **load_fashion_mnist_data:** Loads Fashion MNIST, normalizes and flattens the images, and creates DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_iris_data(batch_size=32):\n",
    "    data = load_iris()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    # Convert to torch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    input_dim = X_train.shape[1]\n",
    "    num_classes = len(np.unique(y))\n",
    "    return train_loader, test_loader, input_dim, num_classes\n",
    "\n",
    "def load_fashion_mnist_data(batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),  # Normalize while still an image (shape: [C, H, W])\n",
    "        transforms.Lambda(lambda x: x.view(-1))  # Then flatten the tensor\n",
    "    ])\n",
    "    train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    input_dim = 28 * 28  # FashionMNIST images are 28x28\n",
    "    num_classes = 10\n",
    "    return train_loader, test_loader, input_dim, num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation Function\n",
    "\n",
    "This function trains a model for a fixed number of epochs using the Adam optimizer and cross-entropy loss.\n",
    "It then evaluates the model on the test set and prints a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation function\n",
    "def train_model(model, train_loader, test_loader, epochs=50, lr=1e-3, device='cpu', print_every=10):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        if (epoch+1) % print_every == 0 or epoch == 0 or epoch == epochs-1:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\", flush=True)\n",
    "    \n",
    "    # Evaluation on test set\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}\", flush=True)\n",
    "    print(\"\\nClassification Report:\", flush=True)\n",
    "    clf_report = classification_report(all_labels, all_preds, zero_division=0, output_dict=True)\n",
    "    print(classification_report(all_labels, all_preds, zero_division=0), flush=True)\n",
    "    \n",
    "    # Return metrics as a dictionary.\n",
    "    return {\"test_loss\": test_loss, \"test_accuracy\": accuracy, \"classification_report\": clf_report}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Runner\n",
    "\n",
    "This function runs experiments on a specified dataset ('iris' or 'fashion_mnist') by:\n",
    "\n",
    "- Training an MLP model.\n",
    "- Training an RBF model.\n",
    "- Training a Hybrid model (using the pretrained MLPâ€™s hidden layer).\n",
    "\n",
    "For the hybrid model, the MLPâ€™s parameters are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Updated Experiment Runner for Activation Experiments\n",
    "def run_activation_experiments(dataset_name, device='cpu'):\n",
    "    \"\"\"\n",
    "    Runs experiments on the specified dataset.\n",
    "    1. Trains a pure RBF model as a baseline.\n",
    "    2. For each activation function:\n",
    "         - Trains an MLP.\n",
    "         - Trains a Hybrid model (with a skip connection) using the MLP's features.\n",
    "    Returns a list of dictionaries with metrics from each run.\n",
    "    \"\"\"\n",
    "    activation_list = ['relu', 'tanh', 'sigmoid', 'identity', 'softplus', 'elu', 'prelu', 'sinusoid', 'step']\n",
    "    results = []\n",
    "    \n",
    "    if dataset_name == 'iris':\n",
    "        train_loader, test_loader, input_dim, num_classes = load_iris_data()\n",
    "        dataset_info = \"Iris\"\n",
    "        hidden_dim = 32  # MLP's second hidden layer dimension\n",
    "        rbf_units = 32\n",
    "        gamma = 1.0\n",
    "    elif dataset_name == 'fashion_mnist':\n",
    "        train_loader, test_loader, input_dim, num_classes = load_fashion_mnist_data()\n",
    "        dataset_info = \"FashionMNIST\"\n",
    "        hidden_dim = 32\n",
    "        rbf_units = 128   # More units for higher-dimensional data\n",
    "        gamma = 0.01      # Lower gamma for better scaling\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset name. Use 'iris' or 'fashion_mnist'.\")\n",
    "    \n",
    "    print(\"=====================================\")\n",
    "    print(f\"Running experiments on {dataset_info} dataset\")\n",
    "    print(\"=====================================\\n\")\n",
    "    \n",
    "    # --- Pure RBF Model Baseline ---\n",
    "    print(\">>> Pure RBF Model Training:\")\n",
    "    rbf_model = RBFNetwork(input_dim=input_dim, rbf_units=rbf_units, num_classes=num_classes, gamma=gamma)\n",
    "    rbf_metrics = train_model(rbf_model, train_loader, test_loader, epochs=30, lr=1e-3, device=device, print_every=10)\n",
    "    results.append({\n",
    "        \"dataset\": dataset_info,\n",
    "        \"model_type\": \"Pure RBF\",\n",
    "        \"activation\": None,\n",
    "        \"test_loss\": rbf_metrics[\"test_loss\"],\n",
    "        \"test_accuracy\": rbf_metrics[\"test_accuracy\"]\n",
    "    })\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # --- Loop over activation functions for MLP and Hybrid ---\n",
    "    for activation in activation_list:\n",
    "        print(f\"\\n--- Testing with activation function: {activation} ---\\n\")\n",
    "        \n",
    "        # Train the MLP model.\n",
    "        print(\"MLP Model Training:\")\n",
    "        mlp_model = MLP(input_dim=input_dim, hidden1=64, hidden2=hidden_dim, num_classes=num_classes, activation=activation)\n",
    "        mlp_metrics = train_model(mlp_model, train_loader, test_loader, epochs=30, lr=1e-3, device=device, print_every=10)\n",
    "        results.append({\n",
    "            \"dataset\": dataset_info,\n",
    "            \"model_type\": \"MLP\",\n",
    "            \"activation\": activation,\n",
    "            \"test_loss\": mlp_metrics[\"test_loss\"],\n",
    "            \"test_accuracy\": mlp_metrics[\"test_accuracy\"]\n",
    "        })\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Train the Hybrid model.\n",
    "        print(\"\\nHybrid Model Training:\")\n",
    "        hybrid_model = HybridNetwork(mlp=mlp_model, hidden_dim=hidden_dim, rbf_units=rbf_units, num_classes=num_classes, gamma=gamma)\n",
    "        hybrid_metrics = train_model(hybrid_model, train_loader, test_loader, epochs=30, lr=1e-3, device=device, print_every=10)\n",
    "        results.append({\n",
    "            \"dataset\": dataset_info,\n",
    "            \"model_type\": \"Hybrid\",\n",
    "            \"activation\": activation,\n",
    "            \"test_loss\": hybrid_metrics[\"test_loss\"],\n",
    "            \"test_accuracy\": hybrid_metrics[\"test_accuracy\"]\n",
    "        })\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution\n",
    "\n",
    "This cell runs experiments on both the Iris and Fashion MNIST datasets. It also visualizes and saves experiment results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "Running experiments on Iris dataset\n",
      "=====================================\n",
      "\n",
      ">>> Pure RBF Model Training:\n",
      "Epoch 1/30, Loss: 1.0665\n",
      "Epoch 10/30, Loss: 1.0164\n",
      "Epoch 20/30, Loss: 0.9548\n",
      "Epoch 30/30, Loss: 0.8834\n",
      "Test Loss: 0.8802, Test Accuracy: 0.6333\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       0.50      1.00      0.67         9\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.44      0.67      0.53        30\n",
      "weighted avg       0.43      0.63      0.50        30\n",
      "\n",
      "\n",
      "--- Testing with activation function: relu ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 1.1297\n",
      "Epoch 10/30, Loss: 0.7212\n",
      "Epoch 20/30, Loss: 0.3849\n",
      "Epoch 30/30, Loss: 0.2403\n",
      "Test Loss: 0.1974, Test Accuracy: 0.9667\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 0.7310\n",
      "Epoch 10/30, Loss: 0.3340\n",
      "Epoch 20/30, Loss: 0.1693\n",
      "Epoch 30/30, Loss: 0.1013\n",
      "Test Loss: 0.0911, Test Accuracy: 0.9667\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "--- Testing with activation function: tanh ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 1.1418\n",
      "Epoch 10/30, Loss: 0.5000\n",
      "Epoch 20/30, Loss: 0.3227\n",
      "Epoch 30/30, Loss: 0.2139\n",
      "Test Loss: 0.1712, Test Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 1.0636\n",
      "Epoch 10/30, Loss: 0.3677\n",
      "Epoch 20/30, Loss: 0.1919\n",
      "Epoch 30/30, Loss: 0.1318\n",
      "Test Loss: 0.1113, Test Accuracy: 0.9667\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "--- Testing with activation function: sigmoid ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 1.1329\n",
      "Epoch 10/30, Loss: 1.0278\n",
      "Epoch 20/30, Loss: 0.8884\n",
      "Epoch 30/30, Loss: 0.6828\n",
      "Test Loss: 0.6534, Test Accuracy: 0.8333\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.44      0.62         9\n",
      "           2       0.69      1.00      0.81        11\n",
      "\n",
      "    accuracy                           0.83        30\n",
      "   macro avg       0.90      0.81      0.81        30\n",
      "weighted avg       0.89      0.83      0.82        30\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 1.1928\n",
      "Epoch 10/30, Loss: 0.4611\n",
      "Epoch 20/30, Loss: 0.3193\n",
      "Epoch 30/30, Loss: 0.2334\n",
      "Test Loss: 0.2148, Test Accuracy: 0.9333\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.78      0.88         9\n",
      "           2       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.95      0.93      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n",
      "\n",
      "--- Testing with activation function: identity ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 0.9547\n",
      "Epoch 10/30, Loss: 0.3592\n",
      "Epoch 20/30, Loss: 0.2467\n",
      "Epoch 30/30, Loss: 0.1611\n",
      "Test Loss: 0.1227, Test Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 1.0869\n",
      "Epoch 10/30, Loss: 0.3908\n",
      "Epoch 20/30, Loss: 0.2405\n",
      "Epoch 30/30, Loss: 0.1666\n",
      "Test Loss: 0.1401, Test Accuracy: 0.9667\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "--- Testing with activation function: softplus ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 1.1152\n",
      "Epoch 10/30, Loss: 0.7036\n",
      "Epoch 20/30, Loss: 0.3905\n",
      "Epoch 30/30, Loss: 0.2676\n",
      "Test Loss: 0.2127, Test Accuracy: 0.9667\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 1.4400\n",
      "Epoch 10/30, Loss: 0.5283\n",
      "Epoch 20/30, Loss: 0.2679\n",
      "Epoch 30/30, Loss: 0.1707\n",
      "Test Loss: 0.1599, Test Accuracy: 0.9667\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "--- Testing with activation function: elu ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 1.1019\n",
      "Epoch 10/30, Loss: 0.4584\n",
      "Epoch 20/30, Loss: 0.2597\n",
      "Epoch 30/30, Loss: 0.1540\n",
      "Test Loss: 0.1122, Test Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 1.0874\n",
      "Epoch 10/30, Loss: 0.3333\n",
      "Epoch 20/30, Loss: 0.1660\n",
      "Epoch 30/30, Loss: 0.1123\n",
      "Test Loss: 0.0973, Test Accuracy: 0.9667\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "--- Testing with activation function: prelu ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 1.0142\n",
      "Epoch 10/30, Loss: 0.4979\n",
      "Epoch 20/30, Loss: 0.2973\n",
      "Epoch 30/30, Loss: 0.1838\n",
      "Test Loss: 0.1338, Test Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 1.2601\n",
      "Epoch 10/30, Loss: 0.4445\n",
      "Epoch 20/30, Loss: 0.2321\n",
      "Epoch 30/30, Loss: 0.1350\n",
      "Test Loss: 0.1051, Test Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "--- Testing with activation function: sinusoid ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 1.1128\n",
      "Epoch 10/30, Loss: 0.4191\n",
      "Epoch 20/30, Loss: 0.2635\n",
      "Epoch 30/30, Loss: 0.1670\n",
      "Test Loss: 0.1234, Test Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 1.0356\n",
      "Epoch 10/30, Loss: 0.3045\n",
      "Epoch 20/30, Loss: 0.1353\n",
      "Epoch 30/30, Loss: 0.0904\n",
      "Test Loss: 0.0702, Test Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "--- Testing with activation function: step ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 1.0582\n",
      "Epoch 10/30, Loss: 0.6336\n",
      "Epoch 20/30, Loss: 0.4467\n",
      "Epoch 30/30, Loss: 0.3936\n",
      "Test Loss: 0.3581, Test Accuracy: 0.9000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.67      0.80         9\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.93      0.89      0.89        30\n",
      "weighted avg       0.92      0.90      0.90        30\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 0.9795\n",
      "Epoch 10/30, Loss: 0.5099\n",
      "Epoch 20/30, Loss: 0.3795\n",
      "Epoch 30/30, Loss: 0.3476\n",
      "Test Loss: 0.3366, Test Accuracy: 0.9000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.67      0.80         9\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.93      0.89      0.89        30\n",
      "weighted avg       0.92      0.90      0.90        30\n",
      "\n",
      "=====================================\n",
      "Running experiments on FashionMNIST dataset\n",
      "=====================================\n",
      "\n",
      ">>> Pure RBF Model Training:\n",
      "Epoch 1/30, Loss: 2.3133\n",
      "Epoch 10/30, Loss: 1.3672\n",
      "Epoch 20/30, Loss: 1.1849\n",
      "Epoch 30/30, Loss: 1.0006\n",
      "Test Loss: 0.9638, Test Accuracy: 0.6987\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.73      1000\n",
      "           1       0.97      0.87      0.92      1000\n",
      "           2       0.63      0.52      0.57      1000\n",
      "           3       0.66      0.78      0.71      1000\n",
      "           4       0.55      0.68      0.61      1000\n",
      "           5       0.76      0.68      0.71      1000\n",
      "           6       0.38      0.28      0.32      1000\n",
      "           7       0.74      0.77      0.76      1000\n",
      "           8       0.80      0.84      0.82      1000\n",
      "           9       0.75      0.85      0.80      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.70      0.69     10000\n",
      "weighted avg       0.70      0.70      0.69     10000\n",
      "\n",
      "\n",
      "--- Testing with activation function: relu ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 0.5167\n",
      "Epoch 10/30, Loss: 0.2619\n",
      "Epoch 20/30, Loss: 0.2074\n",
      "Epoch 30/30, Loss: 0.1753\n",
      "Test Loss: 0.4035, Test Accuracy: 0.8791\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.84      0.76      0.80      1000\n",
      "           3       0.90      0.86      0.88      1000\n",
      "           4       0.80      0.84      0.82      1000\n",
      "           5       0.96      0.96      0.96      1000\n",
      "           6       0.67      0.71      0.69      1000\n",
      "           7       0.95      0.94      0.94      1000\n",
      "           8       0.97      0.96      0.97      1000\n",
      "           9       0.95      0.96      0.96      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 0.3630\n",
      "Epoch 10/30, Loss: 0.1605\n",
      "Epoch 20/30, Loss: 0.1337\n",
      "Epoch 30/30, Loss: 0.1147\n",
      "Test Loss: 0.4823, Test Accuracy: 0.8759\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.76      0.83      0.80      1000\n",
      "           3       0.90      0.87      0.89      1000\n",
      "           4       0.83      0.76      0.79      1000\n",
      "           5       0.95      0.96      0.96      1000\n",
      "           6       0.65      0.70      0.67      1000\n",
      "           7       0.94      0.95      0.95      1000\n",
      "           8       0.97      0.96      0.96      1000\n",
      "           9       0.96      0.96      0.96      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "--- Testing with activation function: tanh ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 0.5419\n",
      "Epoch 10/30, Loss: 0.2996\n",
      "Epoch 20/30, Loss: 0.2526\n",
      "Epoch 30/30, Loss: 0.2241\n",
      "Test Loss: 0.3906, Test Accuracy: 0.8666\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      1000\n",
      "           1       0.99      0.95      0.97      1000\n",
      "           2       0.75      0.82      0.78      1000\n",
      "           3       0.86      0.90      0.88      1000\n",
      "           4       0.82      0.76      0.79      1000\n",
      "           5       0.96      0.92      0.94      1000\n",
      "           6       0.70      0.63      0.66      1000\n",
      "           7       0.93      0.92      0.93      1000\n",
      "           8       0.97      0.97      0.97      1000\n",
      "           9       0.91      0.96      0.94      1000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 0.3579\n",
      "Epoch 10/30, Loss: 0.2158\n",
      "Epoch 20/30, Loss: 0.1922\n",
      "Epoch 30/30, Loss: 0.1794\n",
      "Test Loss: 0.4255, Test Accuracy: 0.8684\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1000\n",
      "           1       0.96      0.96      0.96      1000\n",
      "           2       0.77      0.80      0.78      1000\n",
      "           3       0.85      0.87      0.86      1000\n",
      "           4       0.80      0.78      0.79      1000\n",
      "           5       0.96      0.94      0.95      1000\n",
      "           6       0.70      0.66      0.68      1000\n",
      "           7       0.91      0.95      0.93      1000\n",
      "           8       0.96      0.97      0.96      1000\n",
      "           9       0.95      0.94      0.95      1000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "--- Testing with activation function: sigmoid ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 0.8285\n",
      "Epoch 10/30, Loss: 0.2781\n",
      "Epoch 20/30, Loss: 0.2216\n",
      "Epoch 30/30, Loss: 0.1858\n",
      "Test Loss: 0.3656, Test Accuracy: 0.8808\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1000\n",
      "           1       0.98      0.97      0.98      1000\n",
      "           2       0.81      0.79      0.80      1000\n",
      "           3       0.87      0.90      0.88      1000\n",
      "           4       0.79      0.84      0.82      1000\n",
      "           5       0.95      0.96      0.95      1000\n",
      "           6       0.71      0.68      0.69      1000\n",
      "           7       0.93      0.96      0.94      1000\n",
      "           8       0.98      0.96      0.97      1000\n",
      "           9       0.96      0.93      0.95      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 0.3136\n",
      "Epoch 10/30, Loss: 0.1612\n",
      "Epoch 20/30, Loss: 0.1447\n",
      "Epoch 30/30, Loss: 0.1288\n",
      "Test Loss: 0.4874, Test Accuracy: 0.8703\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1000\n",
      "           1       0.98      0.96      0.97      1000\n",
      "           2       0.81      0.76      0.78      1000\n",
      "           3       0.84      0.91      0.87      1000\n",
      "           4       0.78      0.81      0.79      1000\n",
      "           5       0.96      0.94      0.95      1000\n",
      "           6       0.68      0.66      0.67      1000\n",
      "           7       0.91      0.95      0.93      1000\n",
      "           8       0.96      0.97      0.97      1000\n",
      "           9       0.96      0.94      0.95      1000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "--- Testing with activation function: identity ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 0.5399\n",
      "Epoch 10/30, Loss: 0.4103\n",
      "Epoch 20/30, Loss: 0.3949\n",
      "Epoch 30/30, Loss: 0.3864\n",
      "Test Loss: 0.4545, Test Accuracy: 0.8395\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.70      0.75      0.72      1000\n",
      "           3       0.85      0.85      0.85      1000\n",
      "           4       0.73      0.77      0.75      1000\n",
      "           5       0.92      0.93      0.92      1000\n",
      "           6       0.63      0.52      0.57      1000\n",
      "           7       0.92      0.93      0.92      1000\n",
      "           8       0.92      0.94      0.93      1000\n",
      "           9       0.97      0.91      0.94      1000\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 0.4781\n",
      "Epoch 10/30, Loss: 0.3443\n",
      "Epoch 20/30, Loss: 0.3060\n",
      "Epoch 30/30, Loss: 0.2821\n",
      "Test Loss: 0.3831, Test Accuracy: 0.8636\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1000\n",
      "           1       0.98      0.96      0.97      1000\n",
      "           2       0.76      0.79      0.78      1000\n",
      "           3       0.88      0.84      0.86      1000\n",
      "           4       0.79      0.81      0.80      1000\n",
      "           5       0.94      0.96      0.95      1000\n",
      "           6       0.67      0.66      0.67      1000\n",
      "           7       0.90      0.96      0.93      1000\n",
      "           8       0.94      0.96      0.95      1000\n",
      "           9       0.98      0.91      0.94      1000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "--- Testing with activation function: softplus ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 0.5209\n",
      "Epoch 10/30, Loss: 0.2467\n",
      "Epoch 20/30, Loss: 0.1859\n",
      "Epoch 30/30, Loss: 0.1552\n",
      "Test Loss: 0.4373, Test Accuracy: 0.8782\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82      1000\n",
      "           1       0.97      0.97      0.97      1000\n",
      "           2       0.76      0.86      0.81      1000\n",
      "           3       0.87      0.86      0.87      1000\n",
      "           4       0.82      0.80      0.81      1000\n",
      "           5       0.99      0.92      0.96      1000\n",
      "           6       0.76      0.62      0.68      1000\n",
      "           7       0.90      0.97      0.94      1000\n",
      "           8       0.96      0.97      0.96      1000\n",
      "           9       0.96      0.95      0.95      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 0.3364\n",
      "Epoch 10/30, Loss: 0.1350\n",
      "Epoch 20/30, Loss: 0.1104\n",
      "Epoch 30/30, Loss: 0.0943\n",
      "Test Loss: 0.5330, Test Accuracy: 0.8795\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.81      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.79      0.82      0.80      1000\n",
      "           3       0.89      0.88      0.88      1000\n",
      "           4       0.80      0.83      0.81      1000\n",
      "           5       0.96      0.96      0.96      1000\n",
      "           6       0.70      0.69      0.69      1000\n",
      "           7       0.95      0.95      0.95      1000\n",
      "           8       0.92      0.97      0.94      1000\n",
      "           9       0.96      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "--- Testing with activation function: elu ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 0.4993\n",
      "Epoch 10/30, Loss: 0.2477\n",
      "Epoch 20/30, Loss: 0.1877\n",
      "Epoch 30/30, Loss: 0.1527\n",
      "Test Loss: 0.4059, Test Accuracy: 0.8855\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83      1000\n",
      "           1       0.99      0.96      0.98      1000\n",
      "           2       0.77      0.84      0.80      1000\n",
      "           3       0.85      0.92      0.88      1000\n",
      "           4       0.83      0.80      0.81      1000\n",
      "           5       0.97      0.96      0.96      1000\n",
      "           6       0.75      0.70      0.72      1000\n",
      "           7       0.92      0.97      0.94      1000\n",
      "           8       0.98      0.96      0.97      1000\n",
      "           9       0.97      0.93      0.95      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 0.3179\n",
      "Epoch 10/30, Loss: 0.1342\n",
      "Epoch 20/30, Loss: 0.1097\n",
      "Epoch 30/30, Loss: 0.0926\n",
      "Test Loss: 0.5191, Test Accuracy: 0.8769\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.77      0.79      0.78      1000\n",
      "           3       0.87      0.88      0.88      1000\n",
      "           4       0.82      0.76      0.79      1000\n",
      "           5       0.97      0.94      0.96      1000\n",
      "           6       0.68      0.72      0.70      1000\n",
      "           7       0.93      0.96      0.95      1000\n",
      "           8       0.96      0.97      0.97      1000\n",
      "           9       0.95      0.96      0.96      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "--- Testing with activation function: prelu ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 0.5172\n",
      "Epoch 10/30, Loss: 0.2590\n",
      "Epoch 20/30, Loss: 0.2022\n",
      "Epoch 30/30, Loss: 0.1656\n",
      "Test Loss: 0.4228, Test Accuracy: 0.8810\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.81      0.81      0.81      1000\n",
      "           3       0.90      0.86      0.88      1000\n",
      "           4       0.75      0.87      0.81      1000\n",
      "           5       0.98      0.94      0.96      1000\n",
      "           6       0.72      0.63      0.67      1000\n",
      "           7       0.93      0.97      0.95      1000\n",
      "           8       0.96      0.97      0.97      1000\n",
      "           9       0.95      0.95      0.95      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 0.3424\n",
      "Epoch 10/30, Loss: 0.1442\n",
      "Epoch 20/30, Loss: 0.1194\n",
      "Epoch 30/30, Loss: 0.1029\n",
      "Test Loss: 0.4904, Test Accuracy: 0.8838\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1000\n",
      "           1       0.98      0.97      0.98      1000\n",
      "           2       0.81      0.78      0.80      1000\n",
      "           3       0.89      0.88      0.89      1000\n",
      "           4       0.79      0.84      0.82      1000\n",
      "           5       0.97      0.95      0.96      1000\n",
      "           6       0.71      0.69      0.70      1000\n",
      "           7       0.95      0.95      0.95      1000\n",
      "           8       0.96      0.96      0.96      1000\n",
      "           9       0.95      0.96      0.95      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "--- Testing with activation function: sinusoid ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 0.5327\n",
      "Epoch 10/30, Loss: 0.3353\n",
      "Epoch 20/30, Loss: 0.3115\n",
      "Epoch 30/30, Loss: 0.3115\n",
      "Test Loss: 0.4780, Test Accuracy: 0.8368\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78      1000\n",
      "           1       0.94      0.96      0.95      1000\n",
      "           2       0.71      0.79      0.75      1000\n",
      "           3       0.87      0.78      0.83      1000\n",
      "           4       0.78      0.74      0.76      1000\n",
      "           5       0.92      0.90      0.91      1000\n",
      "           6       0.62      0.60      0.61      1000\n",
      "           7       0.91      0.93      0.92      1000\n",
      "           8       0.96      0.91      0.93      1000\n",
      "           9       0.94      0.94      0.94      1000\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 0.4891\n",
      "Epoch 10/30, Loss: 0.3209\n",
      "Epoch 20/30, Loss: 0.3095\n",
      "Epoch 30/30, Loss: 0.3022\n",
      "Test Loss: 0.5047, Test Accuracy: 0.8349\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      1000\n",
      "           1       0.96      0.96      0.96      1000\n",
      "           2       0.72      0.75      0.73      1000\n",
      "           3       0.85      0.80      0.83      1000\n",
      "           4       0.67      0.84      0.75      1000\n",
      "           5       0.91      0.93      0.92      1000\n",
      "           6       0.67      0.56      0.61      1000\n",
      "           7       0.91      0.91      0.91      1000\n",
      "           8       0.95      0.91      0.93      1000\n",
      "           9       0.95      0.91      0.93      1000\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "\n",
      "--- Testing with activation function: step ---\n",
      "\n",
      "MLP Model Training:\n",
      "Epoch 1/30, Loss: 1.3316\n",
      "Epoch 10/30, Loss: 0.9444\n",
      "Epoch 20/30, Loss: 0.7313\n",
      "Epoch 30/30, Loss: 0.7124\n",
      "Test Loss: 0.7395, Test Accuracy: 0.7411\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74      1000\n",
      "           1       0.92      0.93      0.92      1000\n",
      "           2       0.61      0.60      0.61      1000\n",
      "           3       0.70      0.79      0.75      1000\n",
      "           4       0.60      0.72      0.66      1000\n",
      "           5       0.78      0.73      0.75      1000\n",
      "           6       0.45      0.25      0.32      1000\n",
      "           7       0.73      0.91      0.81      1000\n",
      "           8       0.92      0.83      0.87      1000\n",
      "           9       0.89      0.89      0.89      1000\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.73      0.74      0.73     10000\n",
      "weighted avg       0.73      0.74      0.73     10000\n",
      "\n",
      "\n",
      "Hybrid Model Training:\n",
      "Epoch 1/30, Loss: 0.8113\n",
      "Epoch 10/30, Loss: 0.6579\n",
      "Epoch 20/30, Loss: 0.6106\n",
      "Epoch 30/30, Loss: 0.5811\n",
      "Test Loss: 0.6149, Test Accuracy: 0.7769\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74      1000\n",
      "           1       0.96      0.94      0.95      1000\n",
      "           2       0.69      0.64      0.66      1000\n",
      "           3       0.74      0.83      0.79      1000\n",
      "           4       0.68      0.68      0.68      1000\n",
      "           5       0.86      0.81      0.84      1000\n",
      "           6       0.49      0.45      0.47      1000\n",
      "           7       0.82      0.91      0.86      1000\n",
      "           8       0.91      0.86      0.88      1000\n",
      "           9       0.88      0.90      0.89      1000\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.78      0.78      0.78     10000\n",
      "weighted avg       0.78      0.78      0.78     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model_type</th>\n",
       "      <th>activation</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Pure RBF</td>\n",
       "      <td>None</td>\n",
       "      <td>0.880204</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris</td>\n",
       "      <td>MLP</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.197446</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.091069</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris</td>\n",
       "      <td>MLP</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.171197</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.111265</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iris</td>\n",
       "      <td>MLP</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.653393</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.214842</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Iris</td>\n",
       "      <td>MLP</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.122733</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.140098</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iris</td>\n",
       "      <td>MLP</td>\n",
       "      <td>softplus</td>\n",
       "      <td>0.212663</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>softplus</td>\n",
       "      <td>0.159899</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Iris</td>\n",
       "      <td>MLP</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.112156</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.097262</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Iris</td>\n",
       "      <td>MLP</td>\n",
       "      <td>prelu</td>\n",
       "      <td>0.133764</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>prelu</td>\n",
       "      <td>0.105129</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iris</td>\n",
       "      <td>MLP</td>\n",
       "      <td>sinusoid</td>\n",
       "      <td>0.123393</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>sinusoid</td>\n",
       "      <td>0.070231</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Iris</td>\n",
       "      <td>MLP</td>\n",
       "      <td>step</td>\n",
       "      <td>0.358066</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>step</td>\n",
       "      <td>0.336559</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model_type activation  test_loss  test_accuracy\n",
       "0     Iris   Pure RBF       None   0.880204       0.633333\n",
       "1     Iris        MLP       relu   0.197446       0.966667\n",
       "2     Iris     Hybrid       relu   0.091069       0.966667\n",
       "3     Iris        MLP       tanh   0.171197       1.000000\n",
       "4     Iris     Hybrid       tanh   0.111265       0.966667\n",
       "5     Iris        MLP    sigmoid   0.653393       0.833333\n",
       "6     Iris     Hybrid    sigmoid   0.214842       0.933333\n",
       "7     Iris        MLP   identity   0.122733       1.000000\n",
       "8     Iris     Hybrid   identity   0.140098       0.966667\n",
       "9     Iris        MLP   softplus   0.212663       0.966667\n",
       "10    Iris     Hybrid   softplus   0.159899       0.966667\n",
       "11    Iris        MLP        elu   0.112156       1.000000\n",
       "12    Iris     Hybrid        elu   0.097262       0.966667\n",
       "13    Iris        MLP      prelu   0.133764       1.000000\n",
       "14    Iris     Hybrid      prelu   0.105129       1.000000\n",
       "15    Iris        MLP   sinusoid   0.123393       1.000000\n",
       "16    Iris     Hybrid   sinusoid   0.070231       1.000000\n",
       "17    Iris        MLP       step   0.358066       0.900000\n",
       "18    Iris     Hybrid       step   0.336559       0.900000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FashionMNIST Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model_type</th>\n",
       "      <th>activation</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>Pure RBF</td>\n",
       "      <td>None</td>\n",
       "      <td>0.963775</td>\n",
       "      <td>0.6987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>MLP</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.403537</td>\n",
       "      <td>0.8791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.482265</td>\n",
       "      <td>0.8759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>MLP</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.390557</td>\n",
       "      <td>0.8666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.425478</td>\n",
       "      <td>0.8684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>MLP</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.365633</td>\n",
       "      <td>0.8808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.487439</td>\n",
       "      <td>0.8703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>MLP</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.454489</td>\n",
       "      <td>0.8395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.383098</td>\n",
       "      <td>0.8636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>MLP</td>\n",
       "      <td>softplus</td>\n",
       "      <td>0.437334</td>\n",
       "      <td>0.8782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>softplus</td>\n",
       "      <td>0.532952</td>\n",
       "      <td>0.8795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>MLP</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.405937</td>\n",
       "      <td>0.8855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.519060</td>\n",
       "      <td>0.8769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>MLP</td>\n",
       "      <td>prelu</td>\n",
       "      <td>0.422799</td>\n",
       "      <td>0.8810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>prelu</td>\n",
       "      <td>0.490419</td>\n",
       "      <td>0.8838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>MLP</td>\n",
       "      <td>sinusoid</td>\n",
       "      <td>0.478036</td>\n",
       "      <td>0.8368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>sinusoid</td>\n",
       "      <td>0.504719</td>\n",
       "      <td>0.8349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>MLP</td>\n",
       "      <td>step</td>\n",
       "      <td>0.739470</td>\n",
       "      <td>0.7411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>step</td>\n",
       "      <td>0.614878</td>\n",
       "      <td>0.7769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset model_type activation  test_loss  test_accuracy\n",
       "0   FashionMNIST   Pure RBF       None   0.963775         0.6987\n",
       "1   FashionMNIST        MLP       relu   0.403537         0.8791\n",
       "2   FashionMNIST     Hybrid       relu   0.482265         0.8759\n",
       "3   FashionMNIST        MLP       tanh   0.390557         0.8666\n",
       "4   FashionMNIST     Hybrid       tanh   0.425478         0.8684\n",
       "5   FashionMNIST        MLP    sigmoid   0.365633         0.8808\n",
       "6   FashionMNIST     Hybrid    sigmoid   0.487439         0.8703\n",
       "7   FashionMNIST        MLP   identity   0.454489         0.8395\n",
       "8   FashionMNIST     Hybrid   identity   0.383098         0.8636\n",
       "9   FashionMNIST        MLP   softplus   0.437334         0.8782\n",
       "10  FashionMNIST     Hybrid   softplus   0.532952         0.8795\n",
       "11  FashionMNIST        MLP        elu   0.405937         0.8855\n",
       "12  FashionMNIST     Hybrid        elu   0.519060         0.8769\n",
       "13  FashionMNIST        MLP      prelu   0.422799         0.8810\n",
       "14  FashionMNIST     Hybrid      prelu   0.490419         0.8838\n",
       "15  FashionMNIST        MLP   sinusoid   0.478036         0.8368\n",
       "16  FashionMNIST     Hybrid   sinusoid   0.504719         0.8349\n",
       "17  FashionMNIST        MLP       step   0.739470         0.7411\n",
       "18  FashionMNIST     Hybrid       step   0.614878         0.7769"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run experiments for both datasets\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "results_iris = run_activation_experiments('iris', device=device)\n",
    "results_fmnist = run_activation_experiments('fashion_mnist', device=device)\n",
    "\n",
    "# Convert results to DataFrames\n",
    "df_iris = pd.DataFrame([r for r in results_iris if r[\"dataset\"]==\"Iris\"])\n",
    "df_fmnist = pd.DataFrame([r for r in results_fmnist if r[\"dataset\"]==\"FashionMNIST\"])\n",
    "\n",
    "# Visualize: Bar charts for test accuracy for each model type and activation.\n",
    "def plot_results(df, dataset_name, save_path):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Create a bar plot grouped by model_type and activation.\n",
    "    for model_type in df[\"model_type\"].unique():\n",
    "        sub_df = df[df[\"model_type\"]==model_type]\n",
    "        # For pure RBF, activation is None; we label it accordingly.\n",
    "        labels = sub_df[\"activation\"].fillna(\"RBF\")\n",
    "        plt.bar(labels, sub_df[\"test_accuracy\"], label=model_type)\n",
    "    plt.title(f\"Test Accuracy on {dataset_name}\")\n",
    "    plt.xlabel(\"Activation Function\")\n",
    "    plt.ylabel(\"Test Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, f\"{dataset_name}_accuracy.png\"))\n",
    "    plt.show()\n",
    "    \n",
    "# Create a unique experiment folder to save results and visualizations.\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "experiment_folder = os.path.join(\"results\", f\"experiment_{timestamp}\")\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "# Plot and save results for Iris and FashionMNIST.\n",
    "plot_results(df_iris, \"Iris\", experiment_folder)\n",
    "plot_results(df_fmnist, \"FashionMNIST\", experiment_folder)\n",
    "\n",
    "# Save the result tables as CSV files.\n",
    "df_iris.to_csv(os.path.join(experiment_folder, \"iris_results.csv\"), index=False)\n",
    "df_fmnist.to_csv(os.path.join(experiment_folder, \"fashion_mnist_results.csv\"), index=False)\n",
    "\n",
    "# Display the tables.\n",
    "print(\"Iris Results:\")\n",
    "display(df_iris)\n",
    "print(\"\\nFashionMNIST Results:\")\n",
    "display(df_fmnist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
